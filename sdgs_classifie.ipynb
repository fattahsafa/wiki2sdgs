{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc9XzaL-7tpn"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWBlhxMq7tpr",
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 38126,
     "status": "ok",
     "timestamp": 1675887000380,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "BtkSsTQN7tps",
    "outputId": "057049db-7cc6-42bd-9b9f-741af512daf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install torch\n",
    "#!pip install torchvision \n",
    "#!pip install transformers\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install -U sentence-transformers\n",
    "#!pip install -U datasets\n",
    "#!pip install -U numpy\n",
    "#!pip install pyyaml\n",
    "#!pip install Pillow\n",
    "#!pip install image\n",
    "#!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1675887020739,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "e6O9foTz7tpu"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2Y-dSZI7tpv"
   },
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55570,
     "status": "ok",
     "timestamp": 1675887122533,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "IHOFtNSP7tpv",
    "outputId": "a5184a4c-5a68-4332-ff45-7fe12adc7b9f"
   },
   "outputs": [],
   "source": [
    "use_colab = False\n",
    "if (use_colab):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    dataset_directory = '/content/drive/MyDrive/Colab/datasets/wikipedia_to_sdgs'\n",
    "    workspace = '/content/drive/MyDrive/Colab/wikipedia_to_sdgs'\n",
    "else:\n",
    "    workspace = '.'\n",
    "\n",
    "sdgs_corpus_titles_path = os.path.join(workspace, 'sdgs_titles.json')\n",
    "corpus_directory = os.path.join(workspace, 'articles')\n",
    "country_articles_file_path = os.path.join(workspace, 'country_articles.json')\n",
    "similarity_output_directory = os.path.join(workspace, 'similarities')\n",
    "similarity_threshold = 0.3\n",
    "sdg_indicator_file_path=os.path.join(workspace, 'sdgs_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb-BXFUz7tpw"
   },
   "source": [
    "# Build the SDG-Similarity Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675783429169,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "A-gksHOl7tpw"
   },
   "outputs": [],
   "source": [
    "def retrieve_wikipedia_article(article_uri):\n",
    "    if article_uri.startswith('http'):\n",
    "        article_title = article_uri.rsplit('/', 1)[-1]\n",
    "        print('Title = ', article_title)\n",
    "    else:\n",
    "        article_title = article_uri\n",
    "    \n",
    "    request= 'https://en.wikipedia.org/w/api.php?format=json&action=query&titles='+article_title+'&prop=extracts&exlimit=max&explaintext&exlimit=max'\n",
    "    response = requests.get(request).json()\n",
    "    pageid = list(response['query']['pages'])[0]\n",
    "    content = response['query']['pages'][pageid]['extract']\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnMmzL0t7tpx"
   },
   "source": [
    "## Get SDG article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675783429169,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "x3opxgaZ7tpy"
   },
   "outputs": [],
   "source": [
    "def retrieve_sdg_article(article_uri):\n",
    "    if 'wikipedia' in article_uri:\n",
    "        article_content = retrieve_wikipedia_article(article_uri)\n",
    "    else:\n",
    "        print('unsupported article source ', article_uri)\n",
    "    \n",
    "    return article_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIFD400m-Jax"
   },
   "source": [
    "## Read the goals titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675783429170,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "g6iQnNpe-Tru",
    "outputId": "5f4b8b31-7eee-4c71-c78e-245ca74fdd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of goals found in the corpus file =  17\n"
     ]
    }
   ],
   "source": [
    "sdgs_corpus_titles_file = open(sdgs_corpus_titles_path, 'r')\n",
    "sdgs_corpus_titles = json.load(sdgs_corpus_titles_file)\n",
    "print('Number of goals found in the corpus file = ', len(sdgs_corpus_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_jhfJIs7tpz"
   },
   "source": [
    "## Download the corpus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1675783430456,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "f30uhniZ7tp0",
    "outputId": "3c86e72f-df4a-47ba-d0c8-e9cd93b30179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving articles for  Goal 1: No Poverty\n",
      "Title =  Sustainable_Development_Goal_1\n",
      "Retrieving articles for  Goal 2: Zero Unger\n",
      "Title =  Sustainable_Development_Goal_2\n",
      "Retrieving articles for  Goal 3: Good Health and Well-being\n",
      "Title =  Sustainable_Development_Goal_3\n",
      "Retrieving articles for  Goal 4: Quality Education\n",
      "Title =  Sustainable_Development_Goal_4\n",
      "Retrieving articles for  Goal 5: Gender Equality\n",
      "Title =  Sustainable_Development_Goal_5\n",
      "Retrieving articles for  Goal 6: Clean Water and Sanitation\n",
      "Title =  Sustainable_Development_Goal_6\n",
      "Retrieving articles for  Goal 7: Affordable and Clean Engergy\n",
      "Title =  Sustainable_Development_Goal_7\n",
      "Retrieving articles for  Goal 8: Decent Work and Economic Growth\n",
      "Title =  Sustainable_Development_Goal_8\n",
      "Retrieving articles for  Goal 9: Industry, Innovation and Infrastructure\n",
      "Title =  Sustainable_Development_Goal_9\n",
      "Retrieving articles for  Goal 10: Reduced Inequalities\n",
      "Title =  Sustainable_Development_Goal_10\n",
      "Retrieving articles for  Goal 11: Sustainable Cities and Communities\n",
      "Title =  Sustainable_Development_Goal_11\n",
      "Retrieving articles for  Goal 12: Responsuble Consumption and Prodcution\n",
      "Title =  Sustainable_Development_Goal_12\n",
      "Retrieving articles for  Goal 13: Climate Action\n",
      "Title =  Sustainable_Development_Goal_13\n",
      "Retrieving articles for  Goal 14: Life Below Water\n",
      "Title =  Sustainable_Development_Goal_14\n",
      "Retrieving articles for  Goal 15: Life on Land\n",
      "Title =  Sustainable_Development_Goal_15\n",
      "Retrieving articles for  Goal 16: Peace, Justice and Strong Institutions\n",
      "Title =  Sustainable_Development_Goal_16\n",
      "Retrieving articles for  Goal 17: Partnerships for the Goals\n",
      "Title =  Sustainable_Development_Goal_17\n"
     ]
    }
   ],
   "source": [
    "sdg_corpus = dict()\n",
    "\n",
    "for goal in sdgs_corpus_titles:\n",
    "    article_contents = []\n",
    "    title = sdgs_corpus_titles[goal]['title']\n",
    "    articles = sdgs_corpus_titles[goal]['articles']\n",
    "    print('Retrieving articles for ', goal+': '+title)\n",
    "    for article in articles:\n",
    "        article_content = retrieve_sdg_article(article)\n",
    "        article_contents.append(article_content)\n",
    "    sdg_corpus[goal+': '+title] = article_contents\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpAE2_BP7tp0"
   },
   "source": [
    "# Feed documents into BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEPcpWm87tp1"
   },
   "source": [
    "## Convert corpus dictionary to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675783430457,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "TVj4wZex7tp2"
   },
   "outputs": [],
   "source": [
    "sdgs_documents_df = pd.DataFrame(columns=['document', 'sdg'])\n",
    "\n",
    "row_index = 0\n",
    "for goal in sdg_corpus:\n",
    "    documents = sdg_corpus[goal]\n",
    "    for document in documents:\n",
    "        row = {'document':document, 'sdg':goal}\n",
    "        sdgs_documents_df.loc[row_index] = row\n",
    "        row_index+=1\n",
    "\n",
    "sdgs = sdgs_documents_df.sdg.values\n",
    "sdgs_documents = sdgs_documents_df.document.values\n",
    "#sorted_goals = np.sort(np.unique(goals))\n",
    "#labels = np.searchsorted(sorted_goals,goals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MME2S4Q-7tp2"
   },
   "source": [
    "# Build the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1675,
     "status": "ok",
     "timestamp": 1675783432126,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "3ulWBhMy7tp2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file /kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file /kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kuacc/users/asafa22/.cache/torch/sentence_transformers/sentence-transformers_bert-base-nli-mean-tokens/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xr9DsM1N-nI1"
   },
   "source": [
    "## Construct the sentence embeddings for the goals titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "655be7de3c50405ab4c51e0c47e00363",
      "e3fd4a1c1fa342bc87b25e08c5ab8eb9",
      "86d4273c274348d6a48d7a995476358b",
      "3898dde64364401c814c74bd715bf6d1",
      "fad61673f6bb46e7ad39a6ec6221aef1",
      "3ef7d17f8d4047cf949202dd8a61ed3f",
      "7b059ad7deed408a96208df49f502637",
      "c9027949493b4de5b0cd040cd8fe0548",
      "7325a3098c444d8f93aa1812c6177c7a",
      "0b1f6844951c44cfa68ad800c831b83c",
      "c258f078db6e4c209010083cb8d2d5e8"
     ]
    },
    "executionInfo": {
     "elapsed": 8980,
     "status": "ok",
     "timestamp": 1675783441089,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "hI5P28Mg-rKZ",
    "outputId": "f48d29ad-030a-430c-9ff9-3e19a0642aae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445fa208a5ab401cbe2fdfc204663511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(17, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdgs_embeddings = model.encode(sdgs_documents, batch_size = 8, show_progress_bar = True)\n",
    "np.shape(sdgs_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8FA32-3-32K"
   },
   "source": [
    "# Find the similarity between the goals documents and the input documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHZweWXYOP_6"
   },
   "source": [
    "## Read the country article dictionary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1675783441093,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "jKsjfSMYOT_a"
   },
   "outputs": [],
   "source": [
    "with open(country_articles_file_path, 'r') as file:\n",
    "    country_articles_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqeMqVEG-9xP"
   },
   "source": [
    "## Construct the documents embeddings for the input documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nxb1zNKpBNwf",
    "outputId": "41167ed2-cbe0-4eba-ea0c-f9004d06005f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start constructing document embeddings for  Jordan\n",
      "Finished constructing document embeddings for  Jordan\n",
      "Start constructing document embeddings for  Lebanon\n",
      "Finished constructing document embeddings for  Lebanon\n",
      "Start constructing document embeddings for  Turkey\n",
      "Finished constructing document embeddings for  Turkey\n",
      "Start constructing document embeddings for  Syria\n",
      "Finished constructing document embeddings for  Syria\n",
      "Start constructing document embeddings for  Egypt\n",
      "Finished constructing document embeddings for  Egypt\n",
      "Start constructing document embeddings for  Iraq\n",
      "Finished constructing document embeddings for  Iraq\n",
      "Start constructing document embeddings for  Saudi Arabia\n",
      "Finished constructing document embeddings for  Saudi Arabia\n",
      "Start constructing document embeddings for  Yemen\n",
      "Finished constructing document embeddings for  Yemen\n",
      "Start constructing document embeddings for  Cyprus\n",
      "Finished constructing document embeddings for  Cyprus\n",
      "Start constructing document embeddings for  Qatar\n",
      "Finished constructing document embeddings for  Qatar\n",
      "Start constructing document embeddings for  Oman\n",
      "Finished constructing document embeddings for  Oman\n",
      "Start constructing document embeddings for  Iran\n",
      "Finished constructing document embeddings for  Iran\n",
      "Start constructing document embeddings for  United Arab Emirates\n",
      "Finished constructing document embeddings for  United Arab Emirates\n",
      "Start constructing document embeddings for  Kuwait\n",
      "Finished constructing document embeddings for  Kuwait\n",
      "Start constructing document embeddings for  Bahrain\n",
      "Finished constructing document embeddings for  Bahrain\n",
      "Start constructing document embeddings for  Morocco\n",
      "Finished constructing document embeddings for  Morocco\n",
      "Start constructing document embeddings for  Tunisia\n",
      "Finished constructing document embeddings for  Tunisia\n",
      "Start constructing document embeddings for  Libya\n",
      "Finished constructing document embeddings for  Libya\n",
      "Start constructing document embeddings for  Sudan\n",
      "Finished constructing document embeddings for  Sudan\n",
      "Start constructing document embeddings for  Mauritania\n",
      "Finished constructing document embeddings for  Mauritania\n",
      "Finished construct the document embeddings for all countries\n"
     ]
    }
   ],
   "source": [
    "countries = country_articles_dict.keys()\n",
    "country_embedding_dict = dict()\n",
    "for country in countries:\n",
    "  print('Start constructing document embeddings for ', country)\n",
    "  article_embeddings = []\n",
    "  articles = country_articles_dict[country]\n",
    "  for article in articles:\n",
    "    article_title = article['title']\n",
    "    article_file_path = os.path.join(corpus_directory, article['path'])\n",
    "    with open(article_file_path, 'r', encoding='utf-8') as file:\n",
    "      content = file.read()\n",
    "      file.close()\n",
    "    article_embedding = model.encode(content, show_progress_bar = False)\n",
    "    article_embeddings.append(article_embedding)\n",
    "  country_embedding_dict[country] = article_embeddings\n",
    "  print('Finished constructing document embeddings for ', country)\n",
    "print('Finished construct the document embeddings for all countries')\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mREQ8F_lJVsW"
   },
   "source": [
    "# Find Similarity between DSGs articles and country articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k_yR0Q4Jduu"
   },
   "source": [
    "## Find cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "unr5nOXjJi0e"
   },
   "outputs": [],
   "source": [
    "country_similarities = dict()\n",
    "for country in country_embedding_dict:\n",
    "  article_embeddings = country_embedding_dict[country]\n",
    "  #for article_embedding in article_embeddings:\n",
    "  similarities = cosine_similarity(article_embeddings, sdgs_embeddings)\n",
    "  country_similarities[country] = similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyi2A0YHPxVN"
   },
   "source": [
    "## Print the similarities to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "--7YwLNRQOo1"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(similarity_output_directory):\n",
    "    os.makedirs(similarity_output_directory)\n",
    "for country in country_similarities.keys():\n",
    "    similarity_file_path = os.path.join(similarity_output_directory,country+'_similarity'+'.csv')\n",
    "    np.savetxt(fname=similarity_file_path, X=country_similarities[country], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoBz1zY3IXlL"
   },
   "source": [
    "## Get the candidate documents for each SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "rO9207nfIXMg"
   },
   "outputs": [],
   "source": [
    "sdgs_similar_documents_dict = dict()\n",
    "for goal_index in range(len(sdgs)):\n",
    "  # get documents with similarity >= 0.5\n",
    "  sdg_similar_documents_dict = dict()\n",
    "  for country in countries:\n",
    "    sdg_similar_documents = []\n",
    "    similarities = country_similarities[country]\n",
    "    #for document_index in range(len(similarities[goal_index])):\n",
    "    for document_index in range(len(similarities)):\n",
    "      if similarities[document_index][goal_index]>=similarity_threshold:\n",
    "        sdg_similar_documents.append(document_index)\n",
    "    sdg_similar_documents_dict[country]=sdg_similar_documents\n",
    "  sdgs_similar_documents_dict[sdgs[goal_index]] = sdg_similar_documents_dict\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S-9KjErc-ZC"
   },
   "source": [
    "# Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnG1qBjzZz0H"
   },
   "source": [
    "## Construct the dataset for the sdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "jt-cW4em2AZp"
   },
   "outputs": [],
   "source": [
    "def build_sdg_dataset(sdg, sdg_index, sdgs_similar_documents_dict, country_sdg_indicator_values):\n",
    "  sdg_dataset = pd.DataFrame(columns=['document','label'])\n",
    "\n",
    "  sdg_country_documents = sdgs_similar_documents_dict[sdg]\n",
    "  row_index = 0\n",
    "  for country in sdg_country_documents.keys():\n",
    "    country_sdg_indicator_value = country_sdg_indicator_values[country][sdg_index-1]\n",
    "    country_article_indecies = sdg_country_documents[country]\n",
    "    country_articles = country_articles_dict[country]\n",
    "    for article_index in country_article_indecies:\n",
    "      article = country_articles[article_index]\n",
    "      article_title = article['title']\n",
    "      article_file_path = os.path.join(corpus_directory, article['path'])\n",
    "      with open(article_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        file.close()\n",
    "      sdg_dataset.loc[row_index] = [content,country_sdg_indicator_value]\n",
    "      row_index+=1\n",
    "  return sdg_dataset\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCSPCFSkgokd"
   },
   "source": [
    "## Select the SDG to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "error",
     "timestamp": 1675887275216,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "numFLkrugnnb",
    "outputId": "c5faaf7a-7215-421f-e031-02260563992f"
   },
   "outputs": [],
   "source": [
    "sdg_index = 1\n",
    "sdg = sdgs[sdg_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqvETQTGgeXK"
   },
   "source": [
    "## Read the sdg indicator values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1675887183972,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -120
    },
    "id": "JqDdsmjOgssQ",
    "outputId": "f88877ba-adc2-4794-a4ef-bbdd6edaaa05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jordan': [0.157, nan, nan], 'Lebanon': [0.82, nan, nan], 'Turkey': [0.102, nan, nan], 'Syria': [0.9, nan, nan], 'Egypt': [0.273, nan, nan], 'Iraq': [0.25, nan, nan], 'Saudi Arabia': [0.2, nan, nan], 'Yemen': [0.55, nan, nan], 'Cyprus': [0.138, nan, nan], 'Qatar': [0.0, nan, nan], 'Oman': [0.0, nan, nan], 'Iran': [0.276, nan, nan], 'United Arab Emirates': [0.0, nan, nan], 'Kuwait': [0.0, nan, nan], 'Bahrain': [0.0, nan, nan], 'Morocco': [0.024, nan, nan], 'Tunisia': [0.034, nan, nan], 'Libya': [0.37, nan, nan], 'Sudan': [0.32, nan, nan], 'Mauritania': [0.063, nan, nan]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100644/4202747890.py:1: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  sdg_indicator_values = pd.read_csv(sdg_indicator_file_path, header=0).set_index('country').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "sdg_indicator_values = pd.read_csv(sdg_indicator_file_path, header=0).set_index('country').T.to_dict('list')\n",
    "print(sdg_indicator_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cD24I906fYnT"
   },
   "source": [
    "## Construct the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "j1S311NgfZSo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is  15047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1db9d3daf64c96b18ff45c61f78cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac0cc997b5a4a539cbc5842632b0c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdg1_dataset = build_sdg_dataset(sdg, sdg_index, sdgs_similar_documents_dict, sdg_indicator_values)\n",
    "print('Number of samples is ', sdg1_dataset.shape[0])\n",
    "dataset = Dataset.from_pandas(sdg1_dataset,preserve_index=False)\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "dataset['train']['document'][:5]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"document\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFbYwAS2r209"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "78XXBaVNr4UD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /kuacc/users/asafa22/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wXpZ1Ymr9i9"
   },
   "source": [
    "## Build the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "BHUvw6XasAoe"
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgil7dnKsDdW"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Yg56veKRsG2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/kuacc/users/asafa22/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10532\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1320\n",
      "  Number of trainable parameters = 66954241\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 37:48, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.079508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.076846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.077795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.074234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.077177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.076113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.076092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.076679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "/kuacc/users/asafa22/.conda/envs/main/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4515\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1320, training_loss=0.005107356111208597, metrics={'train_runtime': 2269.7128, 'train_samples_per_second': 37.122, 'train_steps_per_second': 0.582, 'total_flos': 1.1160974097481728e+16, 'train_loss': 0.005107356111208597, 'epoch': 8.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  logging_strategy=\"epoch\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  per_device_eval_batch_size=32,\n",
    "                                  num_train_epochs=8,\n",
    "                                  save_total_limit = 2,\n",
    "                                  save_strategy = 'no',\n",
    "                                  load_best_model_at_end=False\n",
    "                                  )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GwXUcSUsKHm"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ZA1nHbxKsMBO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model/config.json\n",
      "Model weights saved in model/pytorch_model.bin\n",
      "tokenizer config file saved in tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in tokenizer/special_tokens_map.json\n",
      "loading configuration file model/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"model\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# save the model/tokenizer\n",
    "\n",
    "model.save_pretrained(\"model\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")\n",
    "\n",
    "\n",
    "\n",
    "# load the model/tokenizer\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b1f6844951c44cfa68ad800c831b83c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3898dde64364401c814c74bd715bf6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b1f6844951c44cfa68ad800c831b83c",
      "placeholder": "​",
      "style": "IPY_MODEL_c258f078db6e4c209010083cb8d2d5e8",
      "value": " 3/3 [00:08&lt;00:00,  2.28s/it]"
     }
    },
    "3ef7d17f8d4047cf949202dd8a61ed3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "655be7de3c50405ab4c51e0c47e00363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3fd4a1c1fa342bc87b25e08c5ab8eb9",
       "IPY_MODEL_86d4273c274348d6a48d7a995476358b",
       "IPY_MODEL_3898dde64364401c814c74bd715bf6d1"
      ],
      "layout": "IPY_MODEL_fad61673f6bb46e7ad39a6ec6221aef1"
     }
    },
    "7325a3098c444d8f93aa1812c6177c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b059ad7deed408a96208df49f502637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86d4273c274348d6a48d7a995476358b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9027949493b4de5b0cd040cd8fe0548",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7325a3098c444d8f93aa1812c6177c7a",
      "value": 3
     }
    },
    "c258f078db6e4c209010083cb8d2d5e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9027949493b4de5b0cd040cd8fe0548": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3fd4a1c1fa342bc87b25e08c5ab8eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ef7d17f8d4047cf949202dd8a61ed3f",
      "placeholder": "​",
      "style": "IPY_MODEL_7b059ad7deed408a96208df49f502637",
      "value": "Batches: 100%"
     }
    },
    "fad61673f6bb46e7ad39a6ec6221aef1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
